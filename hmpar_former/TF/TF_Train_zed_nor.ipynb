{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b1eb5-8e73-46fa-97e8-30208fb91eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from embedding_layers import SkeletalInputEmbedding\n",
    "from encoder_layers import TransformerEncoder\n",
    "from decoder_layers import TransformerDecoder\n",
    "import TF_helper_functions as hf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb28bfa-65b6-4023-a035-35036b5aa2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/home/augustine/lfd_ws/src/skill_transfer/hmpar_former/data_process/process_data/'\n",
    "# Base path and file information\n",
    "file_root='24_08_30/'\n",
    "file_name='training_raw_normalize.pkl'\n",
    "\n",
    "model_path='/home/augustine/lfd_ws/src/skill_transfer/hmpar_former/models/'\n",
    "model_name = model_path + '24_08_30_nor_v2.pth'\n",
    "\n",
    "print(model_name)\n",
    "def load_results_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        print(\"load the file: \", filename)\n",
    "        return pickle.load(f)\n",
    "    \n",
    "\n",
    "def process_all_datasets(results, input_length=60, predict_length=60):\n",
    "    all_X_pos, all_X_vel, all_X_acc = [], [], []\n",
    "    all_Y_pos, all_Y_vel, all_Y_acc = [], [], []\n",
    "    discarded_frames = {}\n",
    "\n",
    "    for i in range(1, int((len(results)-6)/3)+1):  # Assuming you have 2 datasets\n",
    "        dataset_key = f'dataset{i}'\n",
    "        norm_pos = results[f'{dataset_key}_normpos']\n",
    "        norm_vel = results[f'{dataset_key}_normvel']\n",
    "        norm_acc = results[f'{dataset_key}_normacc']\n",
    "        # norm_pos = results[f'{dataset_key}_pos']\n",
    "        # norm_vel = results[f'{dataset_key}_vel']\n",
    "        # norm_acc = results[f'{dataset_key}_acc']\n",
    "\n",
    "        # Generate sequences for this dataset\n",
    "        X_pos, X_vel, X_acc, Y_pos, Y_vel, Y_acc = hf.generate_sequences(norm_pos, norm_vel, norm_acc, input_length, predict_length)\n",
    "        \n",
    "        all_X_pos.append(X_pos)\n",
    "        all_X_vel.append(X_vel)\n",
    "        all_X_acc.append(X_acc)\n",
    "        all_Y_pos.append(Y_pos)\n",
    "        all_Y_vel.append(Y_vel)\n",
    "        all_Y_acc.append(Y_acc)\n",
    "\n",
    "        # Calculate discarded frames\n",
    "        total_frames = norm_pos.shape[0]\n",
    "        used_frames = X_pos.shape[0] + input_length + predict_length - 1\n",
    "        print(f\"X_pos: {X_pos.shape[0]}, input_length: {input_length}, predict_length: {predict_length}\")\n",
    "        print(f\"total_frames: {total_frames}, used_frames: {used_frames}\")\n",
    "        discarded = total_frames - used_frames\n",
    "        discarded_frames[dataset_key] = discarded\n",
    "\n",
    "    # Combine sequences from all datasets\n",
    "    combined_X_pos = np.concatenate(all_X_pos)\n",
    "    combined_X_vel = np.concatenate(all_X_vel)\n",
    "    combined_X_acc = np.concatenate(all_X_acc)\n",
    "    combined_Y_pos = np.concatenate(all_Y_pos)\n",
    "    combined_Y_vel = np.concatenate(all_Y_vel)\n",
    "    combined_Y_acc = np.concatenate(all_Y_acc)\n",
    "\n",
    "    return (combined_X_pos, combined_X_vel, combined_X_acc, \n",
    "            combined_Y_pos, combined_Y_vel, combined_Y_acc, \n",
    "            discarded_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b76f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 30\n",
    "predict_length = 2\n",
    "datasetnum=6\n",
    "\n",
    "# Load the results\n",
    "results = load_results_from_pickle(data_path + file_root + file_name)\n",
    "# Process all datasets and get combined sequences\n",
    "(combined_X_pos, combined_X_vel, combined_X_acc, \n",
    " combined_Y_pos, combined_Y_vel, combined_Y_acc, \n",
    " discarded_frames) = process_all_datasets(results, input_length, predict_length)\n",
    "\n",
    "print(\"Combined sequences shapes:\")\n",
    "print(f\"X_pos shape: {combined_X_pos.shape}\")\n",
    "print(f\"X_vel shape: {combined_X_vel.shape}\")\n",
    "print(f\"X_acc shape: {combined_X_acc.shape}\")\n",
    "print(f\"Y_pos shape: {combined_Y_pos.shape}\")\n",
    "print(f\"Y_vel shape: {combined_Y_vel.shape}\")\n",
    "print(f\"Y_acc shape: {combined_Y_acc.shape}\")\n",
    "\n",
    "print(\"\\nDiscarded frames per dataset:\")\n",
    "for dataset, frames in discarded_frames.items():\n",
    "    print(f\"{dataset}: {frames} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8abd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already defined your models and set up your training loop\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    \n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "    # Get the name of each GPU and ensure the right one is being used\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "    # Set and confirm the current device (if multiple GPUs are available)\n",
    "    device = torch.device(\"cuda:0\")  # You can change the index to use a different GPU\n",
    "    print(f\"Using GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# Initialize models\n",
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "num_joints = 6\n",
    "dropout_rate = 0.1\n",
    "dof=3\n",
    "input_dim = num_joints * dof\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "start_token = torch.zeros(1, num_joints, 3).to(device)  # Assuming start token\n",
    "\n",
    "# Assuming sequence length\n",
    "# input_length = 30\n",
    "# predict_length = 2\n",
    "\n",
    "\n",
    "# tgt_mask= create_shifted_mask((input_length-1), num_joints)\n",
    "# tgt_mask = tgt_mask.to(device)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_pos_tensor = torch.tensor(combined_X_pos, dtype=torch.float32)\n",
    "X_vel_tensor = torch.tensor(combined_X_vel, dtype=torch.float32)\n",
    "X_acc_tensor = torch.tensor(combined_X_acc, dtype=torch.float32)\n",
    "\n",
    "Y_pos_tensor = torch.tensor(combined_Y_pos, dtype=torch.float32)\n",
    "Y_vel_tensor = torch.tensor(combined_Y_vel, dtype=torch.float32)\n",
    "Y_acc_tensor = torch.tensor(combined_Y_acc, dtype=torch.float32)\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = TensorDataset(X_pos_tensor, X_vel_tensor, X_acc_tensor, Y_pos_tensor, Y_vel_tensor, Y_acc_tensor)\n",
    "\n",
    "# Data loader\n",
    "\n",
    "train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "\n",
    "#Defining Models\n",
    "embedding = SkeletalInputEmbedding(input_dim).to(device)\n",
    "encoder = TransformerEncoder(embed_dim, num_heads, num_layers, dropout_rate).to(device)\n",
    "decoder = TransformerDecoder(embed_dim, num_heads, num_layers, num_joints, dropout_rate).to(device)\n",
    "\n",
    "# Loss function\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = hf.MaskedMSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.00001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "best_loss = float('inf')\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    print(f'Epoch [{epoch}/{num_epochs}]')\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        # Unpack batch\n",
    "        X_pos_batch, X_vel_batch, X_acc_batch, Y_pos_batch, Y_vel_batch, Y_acc_batch = batch\n",
    "        \n",
    "        # Memory Data\n",
    "        X_pos_batch = X_pos_batch.to(device)\n",
    "        X_vel_batch = X_vel_batch.to(device)\n",
    "        X_acc_batch = X_acc_batch.to(device)\n",
    "\n",
    "        inputembeddings = embedding(X_pos_batch, X_vel_batch)\n",
    "       \n",
    "        memory = encoder(inputembeddings, src_key_padding_mask=None)\n",
    "\n",
    "        # Output Data\n",
    "        Y_pos_batch = Y_pos_batch.to(device)\n",
    "        Y_vel_batch = Y_vel_batch.to(device)\n",
    "        Y_acc_batch = Y_acc_batch.to(device)\n",
    "\n",
    "        #Target Data\n",
    "        Y_pos_target=X_pos_batch[:, -1:, :, :]\n",
    "        Y_vel_target=Y_vel_batch[:,:-1,:,:]\n",
    "        Y_acc_target=Y_acc_batch[:,:-1,:,:]\n",
    "\n",
    "        #Expected Data \n",
    "        \n",
    "        Y_pos_expected=Y_pos_batch[:,1:,:,:]\n",
    "\n",
    "        targetembeddings = embedding(Y_pos_target, Y_vel_target)\n",
    "\n",
    "        # Perform forward pass through decoder\n",
    "        output = decoder(targetembeddings, memory, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "\n",
    "        output = output.where(~torch.isnan(output), torch.zeros_like(output))\n",
    "        Y_pos_expected = Y_pos_expected.where(~torch.isnan(Y_pos_expected), torch.zeros_like(Y_pos_expected))\n",
    "\n",
    "                \n",
    "        # print(\"input embeddings: \", np.shape(inputembeddings))\n",
    "        # print(\"memory: \", np.shape(memory))\n",
    "        # print(\"target: \", np.shape(targetembeddings))\n",
    "        # print(\"output: \", np.shape(output))\n",
    "        # print(\"Expected output: \", np.shape(Y_pos_expected))\n",
    "        # Compute loss\n",
    "        loss = criterion(output, Y_pos_expected)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate total loss for the epoch\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    # Print or log average loss for the epoch\n",
    "    print(f'Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Save model weights if the current epoch has the best loss\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'embedding_state_dict': embedding.state_dict(),\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss\n",
    "        }, model_name)\n",
    "        print(f'Saved new best model with validation loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
